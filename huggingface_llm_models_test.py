# -*- coding: utf-8 -*-
"""HuggingFace LLM Models Test

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/huggingface-llm-models-test-39105c46-a94d-43c0-a613-1600a4632466.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250318/auto/storage/goog4_request%26X-Goog-Date%3D20250318T183634Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D10d2d931a984e1b5b14c17e78338cb7f2fdaab07b56f80c33a2f9bdaaba5300b6eacae0aaf204f6dca97327b5d1f115afb55c9870267e5b9f426f5c18a8960e87cfbcd03e75c04e9dd2e5fb7c96b299ed6de80f41ede0e6b6ec920ef505e47a68157dbf914330ed08c04fb6afae34ecfa98e8b87e4d3542b57badb4e1208d4a3128d403bc40600b525edf74d73113ef6901c42a0c35deb4ab90929f4a7ef6f78a1426d696ee4985dce554f8e5912e97ec5b73065134ee991db12fb6a40417f6d3f45c682d41ca684b34513923256814c16b5c67dfa1fe068a8f2e0c67c298549cb04a08d5fee8d15fe307968ef2d652878b61fd3c2801e49b65905e1b0d56ff7

Acompanhe nossos cursos em oceanbrasil.com

Setup:
* Habilite Internet: Em session options, Get Phone Verified, Internet ON
* Habilite GPU: Em session options, ex. Accelerator GPU P100
"""

# HF Pipeline Lib - Simplifies model use
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

"""## Choosing a model"""

# Enable GPU for running with CUDA
torch.random.manual_seed(0)
#Microsoft's Open small model (https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-3-mini-4k-instruct",
    device_map="cuda",
    torch_dtype="auto",
    trust_remote_code=True,
)
tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
)
# Generation config
generation_args = {
    "max_new_tokens": 500,
    "return_full_text": False,
    "temperature": 0.5,
    "do_sample": False,
}

"""## Formatting the prompt"""

messages = [
    {
        "role": "user",
        "content": "Qual o sentido da vida?"
    },
]

output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

messages = [
    {
        "role": "system", # Add general instruction or context
        "content": "Responda em formato de poema.",
    },
    {
        "role": "user",
        "content": "Qual o sentido da vida?"
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

"""## Using a LLM for a translation task"""

messages = [
    {
        "role": "user",
        "content": "Traduza para o português a sentença: \"What is the meaning of life?\""
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

"""## Using the LLM for a sentiment analysis task"""

messages = [
    {
        "role": "user",
        "content": "Qual o sentimento da sentença: \"Que ótimo dia! Estudando e aprendendo IA no Ocean!\""
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

messages = [
    {
        "role": "user",
        "content": "Responda com apenas uma palavra qual o sentimento da sentença: \
                    \"Que dia bonito! Eu no Ocean tendo um grande aprendizado sobre IA!!\". \
                    As opções de resposta são [positivo, negativo, neutro]. Resposta:"
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

"""It is more difficult to smaller models to understand complex prompts.

We can also try set lower temperature.

Large models are better on following instructions. Ex. Gemini or chatGPT.

## Using Few-shot prompt engineering
"""

messages = [
    {
        "role": "system",
        "content": "Você é um assitente de IA que realiza análise de sentimentos. As opções são: Positivo, Negativo e Neutro."
    },
    {
        "role": "user",
        "content": "Mensagem: Essa notícia é muito boa para o mercado de ações. Devemos esperar mais crescimento."
    },
    {
        "role": "assistant",
        "content": "Sentimento: Positivo."
    },
    {
        "role": "user",
        "content": "Mensagem: Esse filme é muito entediante. Não vou conseguir terminar de assistir."
    },
    {
        "role": "assistant",
        "content": "Sentimento: Negativo."
    },
    {
        "role": "user",
        "content": "Mensagem: Não sei o que dizer sobre o assunto. Ainda não estudei o suficiente."
    },
    {
        "role": "assistant",
        "content": "Sentimento: Neutro."
    },
    {
        "role": "user",
        "content": "Mensagem: Que dia bonito! Eu no Ocean tendo um grande aprendizado sobre IA!!"
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

"""## Using LMMs in chat applications"""

messages = [
    {
        "role": "user",
        "content": "Apresente três ideias de atividades para um fim de semana em família."
    },
]
output = pipe(messages, **generation_args)
print(output[0]['generated_text'])

messages_2 = [
    {
        "role": "user",
        "content": "Acrescente uma quarta ideia."
    },
]
output2 = pipe(messages_2, **generation_args)
print(output2[0]['generated_text'])

"""LLM models do not keep context for sequential prompts.

In chat application we must keep the sequential prompts and responses.
"""

messages = [
    {
        "role": "user",
        "content": "Apresente três ideias de atividades para um fim de semana em família."
    },
    {
        "role": "assistant",
        "content": "1. **Piñata e Comida Típica:** Organize uma festa de piñata em família \
        onde cada membro da família pode escolher um item para adicionar à piñata. Depois \
        de quebrá-la, todos podem compartilhar uma refeição típica da sua cultura ou região,\
        como paella, tacos, ou pizza.2. **Jogo de Esconde-Esconde com Roupas:** Transforme \
        o jogo de esconde-esconde clássico em algo mais divertido e criativo, fazendo com \
        que cada membro da família esconda uma peça de roupa em casa e depois tente \
        encontrá-las. Você pode adicionar desafios como encontrar roupas de determinados\
        tipos de pessoas ou de épocas específicas.3. **Caminhada de Aventura:** Planeje \
        uma caminhada ou trilha em um parque local ou área natural próxima. Prepare uma \
        lista de itens para a viagem, como lanches, água, e roupas apropriadas. Durante \
        a caminhada, cada membro da família pode escolher um animal ou planta para aprender\
        sobre."
    },
    {
        "role": "user",
        "content": "Acrescente uma nova ideia."
    },
]
output2 = pipe(messages, **generation_args)
print(output2[0]['generated_text'])

